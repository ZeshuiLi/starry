{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enforcing physical stellar intensity profiles\n",
    "As with planet surfaces, we should require that stellar surfaces have non-negative intensities everywhere. But for most realistic applications, it makes sense to also require that the intensities monotonically decrease toward the limb. Stars get darker toward the limb because the limb probes regions higher up in the star's photosphere, which are cooler and therefore dimmer. In `starry`, we can efficiently enforce these two conditions using [Sturm's theorem](https://en.wikipedia.org/wiki/Sturm%27s_theorem). The `is_physical()` method checks if the map is non-negative and if the limb darkening is monotonic everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import starry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "import emcee\n",
    "from tqdm import tqdm\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlikeSturm(p, map):\n",
    "    \"\"\"Compute the log likelihood using constraints based on Sturm's theorem.\"\"\"\n",
    "    # Set the coeffs\n",
    "    map[:] = p\n",
    "    \n",
    "    # Place some very loose bounds\n",
    "    if np.any(p < -2) or np.any(p > 2):\n",
    "        return -np.inf\n",
    "    \n",
    "    # Determine if it is positive semi-definite and monotonically decreasing\n",
    "    if map.is_physical():\n",
    "        return 0\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "def compute(lmax=1, nsteps=10000, scale=1e-4, lnlike=lnlikeSturm):\n",
    "    \"\"\"Run MCMC to find the PSD regions of parameter space.\"\"\"\n",
    "    # Instantiate the map\n",
    "    map = starry.Map(lmax)\n",
    "\n",
    "    # Run MCMC\n",
    "    ndim = lmax\n",
    "    nwalk = ndim * 2\n",
    "    p0 = [scale * np.random.randn(ndim) for k in range(nwalk)]\n",
    "    sampler = emcee.EnsembleSampler(nwalk, ndim, lnlike, args=[map])\n",
    "    for i in tqdm(sampler.sample(p0, iterations=nsteps), total=nsteps):\n",
    "        pass\n",
    "\n",
    "    # Plot the corner plot\n",
    "    labels = [r\"$u_{%d}$\" % l for l in range(1, lmax + 1)]\n",
    "    samples = sampler.flatchain[np.where(sampler.flatlnprobability == 0)]\n",
    "    fig = corner.corner(samples, labels=labels, bins=50);\n",
    "    for ax in fig.axes:\n",
    "        ax.xaxis.label.set_fontsize(20)\n",
    "        ax.yaxis.label.set_fontsize(20)\n",
    "    \n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out what the allowed parameter space for `u_1` and `u_2` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = compute(lmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually compare these to the simple, analytic expressions from [Kipping (2013)](https://arxiv.org/abs/1308.0009):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlikeKipping(p, map):\n",
    "    \"\"\"Compute the log likelihood using the constraints from Kipping for quadratic limb darkening.\"\"\"\n",
    "    # Set the coeffs\n",
    "    map[:] = p\n",
    "    \n",
    "    # Place some very loose bounds\n",
    "    if np.any(p < -10) or np.any(p > 10):\n",
    "        return -np.inf\n",
    "    \n",
    "    # Determine if it is positive semi-definite and monotonic\n",
    "    u1 = p[0]\n",
    "    u2 = p[1]\n",
    "    if (u1 + u2 < 1) and (u1 > 0) and (u1 + 2 * u2 > 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = compute(lmax=2, lnlike=lnlikeKipping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Now, just for fun, let's look at the parameter space for a higher order map (back to using Sturm's theorem now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = compute(lmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = compute(lmax=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

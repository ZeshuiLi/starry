{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Determine if this is a benchmarking run\n",
    "try:\n",
    "    __benchmark__\n",
    "except NameError:\n",
    "    __benchmark__ = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick starry.grad tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll go over how to use the derivatives computed by `starry.grad` to help in optimization/inference problems. Since the equations in `starry` are all analytic, the code uses [autodifferentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) to analytically (and quickly) compute gradients of the model with respect to all input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import starry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "np.random.seed(8765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, before we get started, let's write a quick function to show side-by-side images of the map as it rotates about its axis. This will help us visualize our original map and the inferred one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(map, axis=[0, 1, 0], res=100, nframes=8):\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, res), np.linspace(-1, 1, res))\n",
    "    theta = np.linspace(0, 360, nframes, endpoint=False)\n",
    "    fig, ax = pl.subplots(1, nframes, figsize=(2 * nframes, 2))\n",
    "    for n in range(nframes):\n",
    "        I = [map.evaluate(axis=axis, theta=theta[n], x=x[j], y=y[j]) for j in range(res)]\n",
    "        ax[n].imshow(I, origin=\"lower\", interpolation=\"none\", cmap='plasma', extent=(-1, 1, -1, 1))\n",
    "        ax[n].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a low degree ($l_{max} = 5$) map of the Earth and plot it using our `show()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 5\n",
    "earth = starry.Map(lmax)\n",
    "earth.load_image('earth')\n",
    "show(earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "if __benchmark__:\n",
    "    assert np.allclose(earth.evaluate(x=[0, 0.2, 0.7, 0.99],y=[0, 0.3, 0.4, 0]), \n",
    "                       np.array([0.40127585, 0.66505788, 0.41675531, 0.15982961]))\n",
    "    assert np.allclose(np.array([earth[5,m] for m in range(-5, 6)]),\n",
    "                       np.array([-0.1418789, 0.06168199, -0.19398174, -0.0186274, 0.06740396,\n",
    "                                 -0.02105715, 0.06642807, -0.00887614, -0.0654446, 0.04427496,\n",
    "                                 -0.00235343]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not terrible! Africa and Europe are kind of one big blob, but you can pick out the Americas, Asia, and a smudge that looks to be Australia. Let's try to recover this map from some occultation light curves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic occultation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to pretend that there's an occultor of radius $r_o = 0.1$ tracing random paths across the surface of our planet as it rotates. Say we observe 20 of these occultations, each with ~100 cadences. Say we also have a ridiculously good telescope and our SNR is huge, so I'm not going to bother noising the data (though you're encouraged to play around with this!) \n",
    "\n",
    "Let's generate some fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 100\n",
    "nevents = 20\n",
    "ro = 0.1\n",
    "xo = []\n",
    "yo = []\n",
    "theta = []\n",
    "dy = []\n",
    "n = 0\n",
    "while n < nevents:\n",
    "    # Randomize the occultor path. We randomly pick\n",
    "    # a minimum impact parameter `ymin`, the angle of\n",
    "    # the transit chord `alpha`, and the rotational\n",
    "    # phase of the planet `theta`:\n",
    "    ymin = 2 * np.random.random() - 1\n",
    "    alpha = np.pi * np.random.random() - np.pi / 2\n",
    "    x = np.linspace(-1.5, 1.5, npts)\n",
    "    y = ymin + x * np.tan(alpha)\n",
    "    inds = x ** 2 + y ** 2 <= 1.5 ** 2\n",
    "    if len(x[inds]) > 10:\n",
    "        xo.append(x[inds])\n",
    "        yo.append(y[inds])\n",
    "        dy.append(ro / np.cos(alpha))\n",
    "        theta.append(np.ones_like(x[inds]) * np.random.random() * 360)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our occultation parameters, let's compute the light curves for each event using `starry` and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rays the occultor traces\n",
    "fig = pl.figure(figsize=(14, 4))\n",
    "ax = pl.subplot2grid((3, 10), (0, 0), rowspan=3, colspan=4)\n",
    "res = 100\n",
    "x, y = np.meshgrid(np.linspace(-1, 1, res), np.linspace(-1, 1, res))\n",
    "I = [earth.evaluate(x=x[j], y=y[j]) for j in range(res)]\n",
    "ax.imshow(I, origin=\"lower\", interpolation=\"none\", cmap='plasma', extent=(-1, 1, -1, 1))\n",
    "for i in range(nevents):\n",
    "    ax.fill_between(xo[i], yo[i] - dy[i], yo[i] + dy[i], color='w', alpha=0.5)\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim(-1 - ro, 1 + ro);\n",
    "ax.set_ylim(-1 - ro, 1 + ro);\n",
    "ax.axis('off');\n",
    "\n",
    "# Plot the light curves\n",
    "axlc = np.array([[pl.subplot2grid((4, 10), (i, j)) for i in range(4)] for j in range(4, 9)]).flatten()\n",
    "flux = [None for i in range(nevents)]\n",
    "for i in range(nevents):\n",
    "    flux[i] = earth.flux(xo=xo[i], yo=yo[i], ro=ro, theta=theta[i])\n",
    "    axlc[i].plot(flux[i])\n",
    "    axlc[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "if __benchmark__:\n",
    "    assert np.allclose(flux[3][10:15], np.array([0.97717466, 0.97717466, 0.97668376, 0.97571509, 0.97447185]))\n",
    "    assert np.allclose(flux[7][30:35], np.array([0.59307336, 0.59276075, 0.59246805, 0.59221149, 0.59200468]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those look pretty cool -- the information content of these light curves is huge! To make the inference problem easier, let's concatenate all the events into a single dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xo = np.concatenate(xo)\n",
    "yo = np.concatenate(yo)\n",
    "theta = np.concatenate(theta)\n",
    "flux = np.concatenate(flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exocartography!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to be exocartographers. Armed with our dataset (the `xo`, `yo`, `theta`, and `flux` arrays), our task is to find the $(l_{max} + 1)^2 = 36$ map coefficients that best explain the features in the light curves. We'll do this by minimizing an objective function, which in this case is just plain old chi-squared: the sum of the squares of the difference between our model and the data, normalized by the standard errors. Since our errors are formally zero (since we didn't add any noise), let's set $\\sigma$ to something small but nonzero so we don't run into numerical issues.\n",
    "\n",
    "Here's our chi-squared function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisq(y, map, xo, yo, ro, theta, flux, sigma=0.001):\n",
    "    # Assign the map coefficients\n",
    "    n = 0\n",
    "    for l in range(1, map.lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            map[l, m] = y[n]\n",
    "            n += 1\n",
    "            \n",
    "    # Compute the model and the chi-squared\n",
    "    model = map.flux(xo=xo, yo=yo, ro=ro, theta=theta)\n",
    "    chi2 = np.sum((model - flux) ** 2) / sigma ** 2\n",
    "\n",
    "    # Return chi squared\n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that we're actually fixing the $Y_{0,0}$ coefficient at unity, so we're really solving for 35 coefficients.)\n",
    "\n",
    "Let's use `scipy.minimize` to minimize the chi-squared. We initialize the solver with random map coefficients (and fix the zeroth coefficient to one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0.1 * np.random.randn((lmax + 1) ** 2)\n",
    "map = starry.Map(lmax)\n",
    "map[0, 0] = 1\n",
    "%time res = minimize(chisq, y[1:], args=(map, xo, yo, ro, theta, flux))\n",
    "print(res.message)\n",
    "print(\"Function calls: %d\" % res.nfev)\n",
    "print(\"Best chi-squared: %.5e\" % res.fun)\n",
    "n = 0\n",
    "for l in range(1, map.lmax + 1):\n",
    "    for m in range(-l, l + 1):\n",
    "        map[l, m] = res.x[n]\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "if __benchmark__:\n",
    "    assert res.fun < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it worked! When I ran this on my MacBook, it took **29 seconds** and **2368 function calls**. Here's what our recovered map looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here's the original map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(earth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're practically identical! Note how tiny the chi-squared is: we definitely found the global minimum. (Remember, though, this is pretty unrealistic since there's no noise!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exo-autodiff-cartography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've been paying close attention, you'll notice I didn't actually pass any gradient information to `scipy.minimize`, so a lot of time was spent by the optimizier trying to figure out which direction (in a 35-dimensional space) to take steps in. This is pretty inefficient, especially since our formulae are analytic and we can easily compute gradients! So let's define a new chi-squared function that returns the gradient of the chi-squared in addition to its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisq_grad(y, map, xo, yo, ro, theta, flux, sigma=0.001):\n",
    "    # Assign the map coefficients\n",
    "    n = 0\n",
    "    for l in range(1, map.lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            map[l, m] = y[n]\n",
    "            n += 1\n",
    "            \n",
    "    # Compute the model and the chi-squared\n",
    "    model = map.flux(xo=xo, yo=yo, ro=ro, theta=theta)\n",
    "    chi2 = np.sum((model - flux) ** 2) / sigma ** 2\n",
    "    \n",
    "    # Get the derivatives of the model w/ respect to y\n",
    "    dmdy = [map.gradient['Y_{%d,%d}' % (l, m)] for l in range(1, map.lmax + 1) for m in range(-l, l + 1)]\n",
    "    \n",
    "    # Now compute the gradient of chi-squared with respect to y\n",
    "    grad = np.sum(2 * (model - flux) * dmdy, axis=1) / sigma ** 2\n",
    "        \n",
    "    # Return chi squared **and** gradient\n",
    "    return chi2, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that whenever `map.flux()` is called, derivatives of the flux are stored in `map.gradient`, which is a dictionary. The derivative of chi-squared with respect to the map coefficients is, from simple calculus:\n",
    "\n",
    "$\\frac{\\mathrm{d}\\ \\chi^2}{\\mathrm{d}\\ \\mathbf{y}} = \\frac{\\mathrm{d}}{\\mathrm{d}\\ \\mathbf{y}} \\left( \\sum \\frac{(m - f)^2}{\\sigma^2} \\right) = \\frac{2}{\\sigma^2} \\sum (m - f) \\frac{\\mathrm{d}\\ m}{\\mathrm{d}\\ \\mathbf{y}}$\n",
    "\n",
    "where $m$ is the model, $\\mathbf{y}$ are the coefficients, $f$ is the flux (our data), and $\\sigma$ are the standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's call the minimizer, but this time we specify `jac=True` to let `scipy` know that our objective function returns the Jacobian (a derivative vector) in addition to the chi-squared.\n",
    "\n",
    "Note that we now have to use `starry.grad.Map` (instead of `starry.Map`) to get `starry` to compute gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0.1 * np.random.randn((lmax + 1) ** 2)\n",
    "map = starry.grad.Map(lmax)\n",
    "map[0, 0] = 1\n",
    "%time res = minimize(chisq_grad, y[1:], args=(map, xo, yo, ro, theta, flux), jac=True)\n",
    "print(res.message)\n",
    "print(\"Function calls: %d\" % res.nfev)\n",
    "print(\"Best chi-squared: %.5e\" % res.fun)\n",
    "n = 0\n",
    "for l in range(1, map.lmax + 1):\n",
    "    for m in range(-l, l + 1):\n",
    "        map[l, m] = res.x[n]\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "if __benchmark__:\n",
    "    assert res.fun < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woot! When I ran this on my laptop, it took **14 seconds** and **60 function calls**. That's more than twice as fast as the previous approach, required 40 times fewer function evaluations, and **just look at that chi-squared!**\n",
    "\n",
    "Here's our recovered map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the original map for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(earth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for now!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
